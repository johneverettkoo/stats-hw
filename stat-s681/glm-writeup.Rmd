---
title: 'GLM-Based Analysis of the Memory Words Task from the MSC Dataset'
author: 'John Koo'
# output: pdf_document
output: html_document
# geometry: "left=1cm,right=1cm,top=1cm,bottom=1.5cm"
urlcolor: blue
header-includes:
- \usepackage{float}
- \usepackage{mathtools}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.pos = 'H', 
                      fig.align = 'center', 
                      fig.height = 5, 
                      fig.width = 8, 
                      fig.dpi = 300)

options(xtable.comment = FALSE, 
        xtable.table.placement = 'H')

import::from(magrittr, `%>%`, `%<>%`)
library(ggplot2)
import::here(load.fmri.data,
             construct.TxV,
             .txv.check,
             construct.t.map,
             plot.tmap,
             .from = 'glm-functions.R')

theme_set(theme_bw())
```

Source code for this document can be found at 
https://github.com/johneverettkoo/stats-hw/tree/master/stat-s681

```{r params}
SUBJECT <- 1
SESSION <- 10
TASK <- 'memorywords'

ALPHA <- .05

REMOVE.GLOBAL = TRUE
```

```{r read_data}
data.list <- load.fmri.data(SUBJECT, SESSION, TASK)
```

For this analysis, we will focus on session `r SESSION` for subject 
`r SUBJECT`. We will look at the T1-weighted scans. This particular session 
consisted of `r dim(data.list$t1w_bold.nifti)[4]` scans of 
$`r dim(data.list$t1w_bold.nifti)[1]` \times 
`r dim(data.list$t1w_bold.nifti)[2]` \times 
`r dim(data.list$t1w_bold.nifti)[3]`$ voxels. Each voxel is 
$`r data.list$t1w_bold.nifti@pixdim[2]` \times
`r data.list$t1w_bold.nifti@pixdim[3]` \times 
`r data.list$t1w_bold.nifti@pixdim[4]`$ mm. The scans were taken at 
$`r data.list$t1w_bold.nifti@pixdim[5]`$ second intervals.

# EDA

Brain mask:

```{r, fig.width = 2, fig.height = 2}
oro.nifti::orthographic(data.list$t1w_mask.nifti)
```

```{r}
data.list$t1w_mask.nifti@.Data %>% 
  table() %>% 
  knitr::kable()
```

```{r}
data.list$t1w_mask.nifti@.Data %>% 
  table() %>% 
  magrittr::divide_by(sum(.)) %>% 
  round(4) %>% 
  knitr::kable()
```

Regressors:

```{r}
data.list$reg.df %>% 
  dplyr::select(time.s,
                reference_bold = ref, 
                trans_x, trans_y, trans_z,
                rot_x, rot_y, rot_z,
                drift, drift_2 = drift2) %>% 
  tidyr::gather('regressor', 'value', -time.s) %>% 
  dplyr::mutate(regressor_type = strsplit(regressor, 
                                          '_', 
                                          fixed = TRUE) %>% 
                  sapply(function(x) x[1])) %>% 
  ggplot() + 
  geom_line(aes(x = time.s, 
                y = value, 
                colour = regressor)) + 
  labs(x = 'time [s]', 
       y = NULL) + 
  facet_grid(regressor_type ~ .,
             scales = 'free_y')
```

# GLM Results and Diagnostics

The model used for this analysis is:

$$Y = X \beta + E$$

... where $Y, E \in \mathbb{R}^{T \times V}$, $T$ is the number of
timepoints/scans and $V$ is the number of voxels in the brain mask (note that 
$V \gg T$). $X \in \mathbb{R}^{T \times p}$ where $p$ is the number of 
parameters (equal to the number of regressors $+ 1$ including an intercept 
term). Only one of the regressors is of interest, and the others are 
nusiance regressors. $\beta \in \mathbb{R}^{p \times V}$, so we are essentially 
fitting a separate regression per voxel. For now, we will assume that the 
entries of $E$ are iid normal, i.e., 
$\epsilon_{ij} \sim \mathcal{N}(0, \sigma^2)$, discounting possible 
autocorrelation along the rows of $Y$.

```{r}
Y.list <- construct.TxV(data.list$t1w_bold.nifti@.Data,
                        data.list$t1w_mask.nifti@.Data, 
                        remove.global = REMOVE.GLOBAL,
                        global.signal = data.list$reg.df$global_signal)
```

```{r check_TxV, eval = FALSE}
# not run
out <- .txv.check(Y.list$Y, Y.list$voxel.ind.array, 100)
assertthat::assert_equal(
  sum(data.list$t1w_bold.nifti@.Data[, , , 100] *
        data.list$t1w_mask.nifti@.Data),
  sum(out, na.rm = TRUE))
heatmap(out[, 20, ], Rowv = NA, Colv = NA)
```

```{r}
# construct data matrix
X <- model.matrix(~ ref + 
                    trans_x + trans_y + trans_z + 
                    rot_x + rot_y + rot_z + 
                    drift + drift2,
                  data = data.list$reg.df)

Y <- Y.list$Y

T <- nrow(Y)
V <- ncol(Y)
p <- ncol(X)

# compute beta hat
XtX.inv <- solve(t(X) %*% X)
beta.hat <- XtX.inv %*% t(X) %*% Y

# compute y hat
Y.hat <- X %*% beta.hat

# compute residuals
E <- Y - Y.hat
RSS <- apply(E, 2, function(x) sum(x ** 2))
sigma2.hat <- RSS / (T - p)

# compute t-statistics
XtX.inv.diag <- diag(XtX.inv)
se.betahat <- sqrt(sigma2.hat * XtX.inv.diag['ref'])
t.stats <- beta.hat['ref', ] / se.betahat
```

The main parameter of interest is $\beta_{task}$ which corresponds to the 
reference BOLD signal based on the task. This value should be approximately 
$t$-distributed under the null that $\beta_{task} = 0$, and we can try 
verifying that it's at least bell-shaped, centered at 0, with slightly heavier
tails than an equivalent normal:

```{r, fig.width = 3, fig.height = 3}
plot(density(t.stats), main = 't statistics for each voxel')
qqnorm(t.stats)
```

Setting the significance level $\alpha = `r ALPHA`$, we can construct 
$t$-maps:

```{r, fig.height = 3, fig.width = 3, cache = FALSE}
t.map <- construct.t.map(t.stats, Y.list$voxel.ind.array, ALPHA)

plot.tmap(t.map[, , 20])
plot.tmap(t.map[, 20, ])
plot.tmap(t.map[20, , ])
```

Note that in the above plots, $t$-statistic values below the cutoff at the 
significance level were set to $0$.

The non-contiguous appearance of the $t$-maps suggests that either the data are 
too noisy (we are looking at just one session) or there's something not quite 
right about the model fit. One thing we can check for (empirically/visually) is 
goodness of fit of the global signal. 

```{r, fig.height = 3}
global.mod <- lm(global_signal ~
                   ref + 
                   trans_x + trans_y + trans_z + 
                   rot_x + rot_y + rot_z + 
                   drift + drift2,
                 data = data.list$reg.df)
yhat <- predict(global.mod)

data.list$reg.df %>% 
  dplyr::mutate(yhat = yhat) %>% 
  ggplot() + 
  geom_line(aes(x = time.s, y = global_signal, colour = 'global signal')) + 
  geom_line(aes(x = time.s, y = yhat, colour = 'model fit')) + 
  geom_line(aes(x = time.s, y = ref * 10 + mean(yhat), 
                colour = 'reference BOLD signal (adj)'))
  labs(x = 'time [s]', y = 'BOLD signal', colour = NULL)
```

Unfortunately in this model, the reference BOLD signal is not a good predictor 
of the observed BOLD signal ($p = 0.69$). Looking back to the plot of the 
regressors, we can see that the rotation along the $x$-axis and translation 
along the $z$-axis appear to correlate strongly with the global signal. 

We can also take a look at the outliers over time:

```{r fig.height = 3}
ggplot(data.list$reg.df) + 
  geom_line(aes(x = time.s, y = non_steady_state_outlier00, colour = '00')) + 
  geom_line(aes(x = time.s, y = non_steady_state_outlier01, colour = '01')) + 
  labs(x = 'time [s]', y = 'outliers', colour = NULL)
```

The plots don't suggest that an abundance of outliers is affecting our models. 
We can nevertheless try cutting off the first few scans (and perhaps the 
last few scans):

```{r, fig.height = 3, fig.width = 3}
Y <- Y[3:(nrow(Y) - 3), ]
X <- X[3:(nrow(X) - 3), ]

T <- nrow(Y)
V <- ncol(Y)
p <- ncol(X)

# compute beta hat
XtX.inv <- solve(t(X) %*% X)
beta.hat <- XtX.inv %*% t(X) %*% Y

# compute y hat
Y.hat <- X %*% beta.hat

# compute residuals
E <- Y - Y.hat
RSS <- apply(E, 2, function(x) sum(x ** 2))
sigma2.hat <- RSS / (T - p)

# compute t-statistics
XtX.inv.diag <- diag(XtX.inv)
se.betahat <- sqrt(sigma2.hat * XtX.inv.diag['ref'])
t.stats <- beta.hat['ref', ] / se.betahat

t.map <- construct.t.map(t.stats, Y.list$voxel.ind.array, ALPHA)

plot.tmap(t.map[, , 20])
plot.tmap(t.map[, 20, ])
plot.tmap(t.map[20, , ])
```