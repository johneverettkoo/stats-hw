{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Framework\n",
    "\n",
    "### Concepts\n",
    "\n",
    "* (probabolistic) model\n",
    "* data/sample\n",
    "* likelihood\n",
    "* maximum likelihood\n",
    "* prior\n",
    "* posterior\n",
    "* maximum a posteriori (MAP)\n",
    "* predictive distribution\n",
    "* conjugate priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: independent coin toss\n",
    "\n",
    "* $P(\\text{heads}) = p$\n",
    "* then $P(HHT) = p \\times p \\times (1 - p)$\n",
    "\n",
    "let \n",
    "\n",
    "$x_i = \\begin{cases}\n",
    "    1 & \\text{if } i^{th} \\text{ toss is heads} \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}$\n",
    "\n",
    "consider 3 cases\n",
    "\n",
    "1. 300 heads, 200 tails\n",
    "2. 3 heads, 2 tails\n",
    "3. 5 heads, 0 tails\n",
    "\n",
    "### maximum likelihood principle\n",
    "\n",
    "pick the model (and parameters) that has the highest likelihood given the sample/data\n",
    "\n",
    "$L(\\theta) = P(\\text{data} \\mid \\theta)$  \n",
    "$\\hat{\\theta} = argmax_\\theta P(\\text{data} \\mid \\theta)$\n",
    "\n",
    "let $\\ell(\\theta) = \\log L(\\theta)$. Then $argmax_\\theta L(\\theta) = argmax_{\\theta} \\ell(\\theta)$\n",
    "\n",
    "### back to the coin toss example\n",
    "\n",
    "$L(p) = \\binom{n}{x} p^x (1-p)^{n-x}$  \n",
    "$\\ell(p) = \\log \\binom{n}{x} + x \\log p + (n-x) \\log (1-p)$\n",
    "\n",
    "where $x$ is the number of heads and $n$ is the total number of coin tosses\n",
    "\n",
    "To maximize w.r.t. $p$, take the derivative and set to 0:\n",
    "\n",
    "$0 = \\frac{x}{p} - \\frac{n-x}{1-p}$  \n",
    "$\\implies \\hat{p} = \\frac{x}{n}$\n",
    "\n",
    "alternatively, consider the prior:\n",
    "\n",
    "* $P(p=.5) = .9$\n",
    "* $P(p=.6) = .1$\n",
    "* $P(p \\not\\in \\{.5, .6\\}) = 0$\n",
    "\n",
    "Another prior:\n",
    "\n",
    "* probability density function $f(p) \\propto p^2 (1-p)^2$ when $p \\in (0, 1)$ and 0 otherwise\n",
    "* $f(p) = \\frac{p^2 (1-p)^2}{30}$\n",
    "\n",
    "given a prior and no data, we can compute the probability of heads:  \n",
    "$P(H) = \\sum_\\theta P(H | \\theta) P(\\theta)$  \n",
    "\n",
    "for the first prior, we have $.9 \\times .5 + .1 \\times .6 = .51$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### posterior distribution\n",
    "\n",
    "if we have data, then we can update our prior belief\n",
    "\n",
    "$P(\\theta \\mid \\text{data})$\n",
    "\n",
    "To compute, we use ...\n",
    "\n",
    "### Bayes' rule\n",
    "\n",
    "$P(\\theta \\mid x) = \\frac{P(x \\mid \\theta) P(\\theta)}{P(x)}$\n",
    "\n",
    "note that $P(x \\mid \\theta) = L(\\theta)$, the likelihood\n",
    "\n",
    "to compute the denominator:\n",
    "\n",
    "$P(x) = \\sum_\\theta P(x | \\theta) P(\\theta)$\n",
    "\n",
    "### back to the coin toss example ...\n",
    "\n",
    "using the first prior, we can compute \n",
    "$P(p=.5 | x) = \\frac{.9 \\times .5^x .5^{n-x}}{.9 \\times .5^x .5^{n-x} + .1 \\times .6^x .4^{n-x}}$\n",
    "\n",
    "for the second prior ...  \n",
    "$f(p | x) = \\frac{f(p) p^x (1-p)^{n-x}}{\\int f(p) p^x (1-p)^{n-x} dp}$  \n",
    "\n",
    "we can avoid doing the integral in the denominator by saying ...  \n",
    "$\\propto p^{x+2} (1-p)^{n-x+2}$  \n",
    "and then noting that probabilities must sum up to or integrate to 1\n",
    "\n",
    "### maximum a posteriori principle\n",
    "\n",
    "choose the model that maximizes the posterior\n",
    "\n",
    "note that this often doesn't require normalizing the posterior distribution (just need to compute the argmax)\n",
    "\n",
    "### back to the coin toss example ...\n",
    "\n",
    "using the prior $f(p) \\propto p^2 (1-p)^2$, we have  \n",
    "$f(p|x) = p^{x+2} (1-p)^{n-x+2}$  \n",
    "and taking the derivative w.r.t. $p$ and setting to 0, we get  \n",
    "$\\hat{p} = \\frac{x+2}{n+4}$\n",
    "\n",
    "### conjugate prior\n",
    "\n",
    "a prior distribution such that the the posterior distribution is of the same family\n",
    "\n",
    "### back to the coin toss example ...\n",
    "\n",
    "we started with\n",
    "\n",
    "* $x \\mid p \\sim Binomial(p)$\n",
    "* $p \\sim Beta(2, 2)$\n",
    "\n",
    "then we get\n",
    "\n",
    "* $p \\mid x \\sim Beta(x + 2, n - x + 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
