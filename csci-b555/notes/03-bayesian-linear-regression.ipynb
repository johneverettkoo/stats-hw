{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall ordinary least squares regression:\n",
    "\n",
    "* $t_i \\stackrel{iid}{\\sim} \\mathcal{N}(f_i, \\beta^{-1})$\n",
    "* $f_i = w^\\top \\phi(x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose we want a prior for $w$\n",
    "\n",
    "* preferably a *conjugate* prior\n",
    "* recall posterior $\\propto$ prior $\\times$ likelihood\n",
    "* then a multivariate normal prior results in a multivariate normal posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**multivariate normal distribution**\n",
    "\n",
    "let $X \\in \\mathbb{R}^p$\n",
    "\n",
    "$X \\sim MVN(\\mu, \\Sigma)$ iff it has density function  \n",
    "$f(x) = (2 \\pi)^{-p/2} |\\Sigma|^{-1/2} \\exp \\big( -\\frac{1}{2} (x - \\mu)^\\top \\Sigma^{-1} (x - \\mu) \\big)$\n",
    "\n",
    "$\\Sigma_{ij} = Cov(X_i, X_j) = Cov(X_j, X_i) = \\Sigma_{ji}$\n",
    "\n",
    "alternative parameterization using precision $Q = \\Sigma^{-1}$:\n",
    "\n",
    "* $X \\sim MVN(\\mu, Q^{-1})$\n",
    "* $f(x) = \\big( \\frac{1}{2 \\pi} \\big)^{p/2} |Q| \\exp \\big( -\\frac{1}{2} (x - \\mu)^\\top Q (x - \\mu) \\big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**theorem**\n",
    "\n",
    "let \n",
    "\n",
    "* $X \\sim F_X$\n",
    "* $y = g(x)$, 1-1 and invertible\n",
    "\n",
    "then\n",
    "\n",
    "* $f_Y(y) = f_X \\big(g^{-1}(y) \\big) \\bigg|\\frac{dg^{-1}}{dy} \\bigg|$\n",
    "\n",
    "for multidimensional random variables\n",
    "\n",
    "* $f_Y(y) = f_X \\big( g^{-1}(y) \\big) \\big| J_{g^{-1}} (y) \\big|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**eigendecomposition of $\\Sigma = V \\Lambda V^\\top$**\n",
    "\n",
    "let $Y = V^\\top (X - \\mu)$ then $X = V Y + \\mu$  \n",
    "$\\Sigma^{-1} = V \\Lambda^{-1} V^\\top$  \n",
    "$|V| = 1$  \n",
    "$|\\Sigma| = |V^\\top \\Lambda V| = |V^\\top| |\\Lambda| |V| = |\\Lambda|$  \n",
    "so we get  \n",
    "$f(y) = (2 \\pi)^{-p/2} |\\Lambda|^{-1/2} \\exp( -\\frac{1}{2} y^\\top \\Lambda^{-1} y)$  \n",
    "where $\\Lambda$ is a diagonal matrix  \n",
    "then $Y_i$'s are iid normal  \n",
    "$f(y) = \\prod_i f(y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Cov(x) = E[(x - \\mu) (x - \\mu)^\\top]$  \n",
    "$= E[z z^\\top]$ (where $z = x - \\mu$)  \n",
    "$= E[Vy (Vy)^\\top]$  \n",
    "$= E[V y y^\\top V^\\top]$  \n",
    "$= V E[y y^\\top] V^\\top$  \n",
    "$= V \\Lambda V^\\top$  \n",
    "$= \\Sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**corollary**\n",
    "\n",
    "suppose $f(x) \\propto e^{a^\\top x} e^{-\\frac{1}{2} x^\\top B x}$\n",
    "\n",
    "then $X \\sim MVN(B^{-1} a, B^{-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0, 0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
