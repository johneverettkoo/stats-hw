{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian networks\n",
    "\n",
    "directed graphical models detailing how each variable affects another\n",
    "\n",
    "directed acyclic graph (DAG) - no looping paths\n",
    "\n",
    "$P(X_1, ..., X_n) = \\prod_i P(X_i \\mid parents(X_i))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** given joint distribution over $X_1, ..., X_n$ as $P(X_1, X_2, ..., X_n)$\n",
    "\n",
    "can write as $P(X_1) P(X_2 | X_1) P(X_3 | X_2, X_1) P(X_4 | X_3, X_2, X_1) \\cdots$\n",
    "\n",
    "but there may not be all direct dependencies (conditional independence)\n",
    "\n",
    "perhaps $X_4$ depends on $X_2$ and $X_3$ but not directly on $X_1$  \n",
    "then even if $X_2$ and $X_3$ depend directly on $X_1$, we can write \n",
    "$P(X_4 | X_3, X_2, X_1) = P(X_4 | X_3, X_2)$"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** bayesian linear regression\n",
    "\n",
    "$t_i$ is generated by $w$, $\\phi(x_i)$, and $\\sigma$ where we observe $t_i$ and $\\phi(x_i)$\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** generative model\n",
    "\n",
    "$t_i \\sim Discrete(\\{p_j\\}_{j=0}^k)$  \n",
    "$x_i \\mid t_i \\sim \\mathcal{N}(\\mu_{t_i}, \\Sigma_{t_i})$\n",
    "\n",
    "so $x_i$ depend on $t_i, \\mu_j, \\Sigma_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "things we would like to solve\n",
    "\n",
    "* $p(x_k) = \\int_{x_1} \\int_{x_2} \\cdots \\int_{x_{k-1}} \\int_{x_{k+1}} \\cdots \\int_{x_n} p(x_1, ..., x_n) dx_1 \\cdots dx_n$\n",
    "* $p(x_k | x_1 = a, x_2 = b, ...)$\n",
    "* $\\arg\\max_{x_k} p(x_k | x_1 = a, ...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** markov blanket\n",
    "\n",
    "given $children(z)$, $parents(z)$, $parents(children(z))$ observed, $z$ is conditionally independent of all other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** markov random field\n",
    "\n",
    "* given an undirected graph $G = V, E$\n",
    "* for any clique (fully connected subgraph) $C \\subset V$, we can write a potential function  \n",
    "$\\psi_C(C) \\geq 0$  \n",
    "note that $C$ is a set of vertices, e.g., if $|C_k| = 3$, then $C_k = \\{0, 0, 0\\}, \\{0, 0, 1\\}, \\{0, 1, 0\\}$, etc.\n",
    "* then the joint probability  \n",
    "$p(x_1, ..., x_n) = \\frac{1}{Z} \\prod_k \\psi_{C_k} (C_k)$  \n",
    "where $Z = \\sum_{x_1, ..., x_n} \\prod_k \\psi_{C_k} (C_k)$  \n",
    "$x_k \\in \\{0, 1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** factor graph\n",
    "\n",
    "two types of nodes\n",
    "\n",
    "* random variables\n",
    "* factors (similar to potential functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on networks\n",
    "\n",
    "**e.g.** \n",
    "\n",
    "we wish to know $P(X_5 \\mid X_1 = x_1, X_8 = x_8)$  \n",
    "$= \\sum_{X_2, X_3, X_4, X_6, X_7, X_9, X_{10}} P(X_1 = x_1) P(X_2) P(X_3) P(X_4 | x_1, X_2, X_3) P(X_6) P(X_5 | X_4, X_6) P(X_7 | X_5) P(X_8 = x_8 | X_5) P(X_{10}) P(X_9 | X_5, X_{10})$\n",
    "\n",
    "but we can simplify this first\n",
    "\n",
    "first sum over $X_7$ since it has one parent and no children:  \n",
    "$\\sum \\cdots \\sum_{X_7} P(X_7 | X_5)$  \n",
    "then we note that $\\sum_{X_7} P(X_7 | X_5) = 1$ since it is a probability\n",
    "\n",
    "we can try to remove $X_{10}$ which has no parents but one child $X_9$ (which has parents $X_5, X_{10}$ and no children  \n",
    "then we get  \n",
    "$\\sum \\cdots \\sum_{X_{10}} P(X_{10}) P(X_9 | X_{10}, X_5)$  \n",
    "$= f_{X_{10}}(x_9, x_5)$\n",
    "\n",
    "this is called ***variable elimination***\n",
    "\n",
    "### belief propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC\n",
    "\n",
    "transitions constructed such that the stationary distribution of the markov chain is the posterior distribution which we want to approximate  \n",
    "taking a long walk in the markov chain and using the last step serves as an implementation of sampling from the posterior  \n",
    "repeat many times to get multiple posterior samples\n",
    "\n",
    "**def** $p(\\cdot)$ is stationary for $T(\\cdot)$ iff $\\forall s_i$, $p(s_i) = \\sum_j p(s_j) T(s_i | s_j)$\n",
    "\n",
    "guaranteed to exist under some conditions on markov chains\n",
    "\n",
    "### Gibbs sampling\n",
    "\n",
    "to sample from distribution over $V_1, ..., V_n$:  \n",
    "repeat:\n",
    "\n",
    "1. pick $i \\in \\{1, .., n\\}$ uniformly\n",
    "2. draw new value for $V_i$ from $p(v_i \\mid v_1, ..., v_{i-1}, v_{i+1}, ..., v_n\\}$\n",
    "\n",
    "**e.g.** \n",
    "\n",
    "* graphical model $X \\to Y \\to Z$\n",
    "* $X \\sim Bernoulli(.6)$\n",
    "* $Y$ can be $a, b, c$ s.t. $p(a, b, c \\mid X=1) = (.3, .3 .6)$ and $p(a, b, c | X=0) = (.1, .6, .3)$\n",
    "* $Z$ is binary s.t. $p(z | Y=a) = .2$, $p(z | Y=b) = .4$, $p(z | Y=c) = .5$\n",
    "* current sample is $(X, Y, Z) = (0, b, 1)$\n",
    "\n",
    "then to resample $Y$,  \n",
    "$p(y) \\propto p(x) p(y|x) p(z|y)$  \n",
    "then we compute this for each $a, b, c$, fixing $X=0$ and $Z=1$,  \n",
    "then normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis Hastings sampling\n",
    "\n",
    "to sample from distribution over $V_1, ..., V_n$  \n",
    "define proposal distribution $q(V' | V)$ s.t. $V, V'$ are assignments to all variables  \n",
    "repeat:\n",
    "\n",
    "1. sample $V' \\sim q(V' | V)$\n",
    "2. calculate $A = \\min(1, \\frac{p(V') q(V | V')}{p(V) q(V'|V)})$\n",
    "3. with probability $A$, let $V \\leftarrow V'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detailed balance\n",
    "\n",
    "* $p$ is the intended distribution\n",
    "* $T$ are the transitions of the markov chain\n",
    "\n",
    "$p(a) T(b | a) = p(b) T(a | b)$\n",
    "\n",
    "1. detailed balance for $p$ $\\implies$ $p$ is stationary for the markov chain  \n",
    "$\\sum_j p(s_j) T(s_i | s_j)$  \n",
    "$= \\sum_j p(s_i) T(s_j | s_i)$  \n",
    "$= p(s_i) \\sum_j T(s_j | s_i)$  \n",
    "$= p(s_i)$\n",
    "2. MH statisfies detailed balance for $p$  \n",
    "$p(a) T(b | a)$  \n",
    "$= p(a) q(b | a) A$  \n",
    "$= \\min(p(a) q(b | a), p(b) q(a | b))$  \n",
    "$= p(b) q(a | b) \\min(1, \\frac{p(a) q(b | a)}{p(b) q(a | b)})$  \n",
    "$= p(b) T(a | b)$\n",
    "3. Gibbs is MH with $A=1$ at every sampling iteration  \n",
    "let $x$ be the current state, and write it as $\\tilde{x}_i, x_r$ s.t. $x_r$ is the rest of the string and $\\tilde{x}_i$ is the current value of $x_i$  \n",
    "let $y = \\hat{x}_i, x_r$ be a potential next state  \n",
    "the proposal distribution is through the conditional probability: $q(y | x) = p(\\hat{x}_i | x_r)$  \n",
    "then the numerator is the same as the denominator in $A$, so we just get $A=1$  \n",
    "$p(y) T(x | y) = p(\\hat{x}_i, x_r) p(\\tilde{x}_i | x_r)$  \n",
    "$= p(\\hat{x}_i | x_r) p(x_r) p(\\tilde{x}_i | x_r)$  \n",
    "$= p(\\hat{x} | x_r) p(\\tilde{x}_i, x_r)$  \n",
    "$= p(x) T(y | x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent dirichlet analysis\n",
    "\n",
    "**def** dirichlet distribution\n",
    "\n",
    "* let $\\mu = \\begin{bmatrix} \\mu_1 \\\\ \\vdots \\\\ \\mu_k \\end{bmatrix}$ \n",
    "such that $\\sum_i \\mu_i = 1$\n",
    "* let $\\alpha \\in \\mathbb{R}^k$ and define $\\alpha_0 = \\sum_i \\alpha_i$\n",
    "* then $\\mu \\sim Dirichlet(\\alpha)$ iff \n",
    "$p(\\mu) = \\frac{\\Gamma(\\alpha_0)}{\\prod \\Gamma(\\alpha_i)} \\prod \\mu_i^{\\alpha_i - 1}$\n",
    "\n",
    "dirichlet is a conjugate prior for a multivariate distribution"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** generative model for LDA\n",
    "\n",
    "* for each $d$, draw $\\theta_{k | d} \\sim Dirichlet(\\theta_d | \\alpha)$\n",
    "* for each $k$, draw $\\phi_{i | k} \\sim Dirichlet(\\phi_k | \\beta)$\n",
    "* for each $d$, for each location $j$ in $d$, \n",
    "    * draw $z^{j, d} \\sim \\theta_{k | d}$\n",
    "    * draw $w^{j, d} \\sim \\phi_{i | k = z^{j, d}}$\n",
    "    \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latent semantics\n",
    "\n",
    "let $w$ be the number of words, $d$ be the number of documents, and $t$ be the number of documents, and pick $q$ dimensions\n",
    "\n",
    "LSA: $C = U D V^\\top$ where $U \\in \\mathbb{R}^w \\times q$ and $V \\in \\mathbb{R}^{q \\times d}$  \n",
    "topic model: $C = \\Phi \\Theta$ where $C \\in \\mathbb{R}^{w \\times t}$ and $\\Theta \\in \\mathbb{R}^{t \\times d}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**inference** on LDA\n",
    "\n",
    "* $N = \\sum N_d$ is total number of words\n",
    "* $N_d$ is number of words in document $d$\n",
    "* $N_k$ is the number of times topic $k$ is used\n",
    "* $N_{k | d}$ is the number of times topic $k$ is used in document $d$\n",
    "* $N_{i|k}$ is the number of times word $i$ is used in topic $k$\n",
    "\n",
    "* prior: $(\\prod_d Dir(\\theta_d | \\alpha)) \\prod_k Dir(\\phi_k | \\beta))$\n",
    "* likelihood: $(\\prod_d \\prod_k \\theta_{k|d}^{N_{k|d}}) (\\prod_k \\prod_i \\phi){i|k}^{N_{i|k}})$\n",
    "* posterior: \n",
    "    * $\\theta_d | D, Z \\sim Dirichlet(\\alpha + N_{k|d})$  \n",
    "    * $phi | D, Z \\sim Dirichlet(\\beta + N_{i|k})$\n",
    "    \n",
    "but this assumes we observe topics $Z$ and have counts $N_k, N_{k|d}, N_{i|k}$\n",
    "\n",
    "gibbs sampling: marginalize $\\phi$, $\\theta$ and sample $Z$  \n",
    "$N^-, N_d^-, N_{k|d}^-, N_{i|k}^-$ are counts without $z^{j, d}, w^{j, d}$  \n",
    "$p(z_k^{j, d} = 1 | D^-, Z^-) p(w^{j, d} = i | z_k^{j, d} = 1) \\propto \\frac{\\alpha_k + N_{k|d}^-}{\\alpha_0 + N_d^-} \\frac{\\beta_i + N_{i|k}^-}{\\beta_0 + N_k^-}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization\n",
    "\n",
    "useful when can't marginalize variables directly  \n",
    "i.e., no closed form of marginal probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** gaussian mixture model\n",
    "\n",
    "model\n",
    "\n",
    "* $Z_i \\sim Discrete(\\{p_j\\})$\n",
    "* $Y_i | Z_i \\sim \\mathcal{N}(\\mu_{Z_i}, \\Sigma_{Z_i})$\n",
    "\n",
    "want to maximize $p(y | p_j, \\mu_j, \\Sigma_j) = \\sum_z p(y, z | p_j, \\mu_j, \\Sigma_j)$\n",
    "\n",
    "but we don't observe the $Z_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** bayesian linear regression\n",
    "\n",
    "$w \\sim \\mathcal{N}(0, \\alpha^{-1} I)$  \n",
    "$t | w \\sim \\mathcal{N}(\\Phi w, \\beta^{-1} I)$\n",
    "\n",
    "want to maximize $p(t | \\alpha, \\beta) = \\int_w p(t | w, \\beta) p(w | \\alpha) dw$\n",
    "\n",
    "we don't observe $\\alpha$, $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**algorithm**\n",
    "\n",
    "initialize $\\theta$\n",
    "\n",
    "until convergence:\n",
    "\n",
    "1. compute $Q(\\theta^{new}, \\theta^{old}) = E_{Z | Y, \\theta^{old}}[\\log p(Y, Z | \\theta^{new})]$  \n",
    "2. set $\\theta^{old} = \\arg\\max_{\\theta^{new}} Q(\\theta^{new}, \\theta^{old})$\n",
    "\n",
    "hill-climbing method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** gaussian mixture model\n",
    "\n",
    "likelihood: $L = \\prod_i \\prod_j (p_j p(y_i | z_i = j))^{z_{ij}}$  \n",
    "$= \\prod_i \\prod_j ( (2 \\pi)^{-d/2} |\\Sigma_j|^{-1/2} e^{-\\frac{1}{2} (y_i - \\mu_j)^\\top \\Sigma_j^{-1} (y_i - \\mu_j)})^{z_{ij}}$\n",
    "\n",
    "then $\\ell = \\sum_i \\sum_j z_{ij} \\log \\alpha_{ij}$ where $\\alpha_{ij}$ is the base of the exponent in the likelihood expression\n",
    "\n",
    "$Q = E[\\sum_{ij} Z_{ij} \\log \\alpha_{ij}^{new}]$\n",
    "$= \\sum_{ij} \\log \\alpha_{ij}^{new} E[Z_{ij}]$\n",
    "$= \\sum_{ij} \\log \\alpha_{ij}^{new} P(Z_{ij} = 1 | Y, \\theta^{old})$  \n",
    "$= \\sum_{ij} \\log \\alpha_{ij}^{new} \\frac{P(Z_{ij} = 1 | \\theta^{old}) P(Y_i | Z_{ij} = 1, \\theta^{old})}{\\sum_l P(Z_{il} = 1 | \\theta^{old}) P(Y_i | Z_{il} = 1, \\theta^{old})}$  \n",
    "$= \\sum_{ij} \\gamma_{ij} \\log \\alpha_{ij}^{new}$  \n",
    "$= \\sum_{ij} \\gamma_{ij} (\\log p_j^{new}  - \\frac{1}{2} \\log |\\Sigma_j| - \\frac{1}{2} (y_i - \\mu_j)^\\top \\Sigma_j^{-1} (y_i - \\mu_j))$\n",
    "\n",
    "$\\gamma_{ij}$ is the probability that $y_i$ is in class $j$ given current $\\mu_j$, $\\Sigma_j$\n",
    "\n",
    "then update:\n",
    "* $n_j = \\sum_i \\gamma_{ij}$ is the \"count\" of $y_i$ in class $j$  \n",
    "* $\\mu_j = n_j^{-1} \\sum_i \\gamma_{ij} y_i$  \n",
    "* $\\Sigma_j = n_j^{-1} \\sum_i \\gamma_{ij} (y_i - \\mu_j)^\\top (y_i - \\mu_j)^\\top$  \n",
    "* $p_j = n_j / n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** bayesian linear regression\n",
    "\n",
    "recall  \n",
    "$S_n = (\\alpha I + \\beta \\Phi^\\top \\Phi)^{-1}$  \n",
    "$m_n = \\beta S_n \\Phi^\\top t$\n",
    "\n",
    "evidence = $p(t) = \\int_w p(w) p(t | w) dw$\n",
    "\n",
    "$p(w, t) \\propto \\alpha^{d/2} e^{-\\frac{\\alpha}{2} w^\\top w} \\beta^{n/2} e^{-\\frac{\\beta}{2} (t - \\Phi w)^\\top (t - \\Phi w)}$\n",
    "\n",
    "$Q = E_{p(w | t, \\alpha^{old}, \\beta^{old})}[\\frac{d}{2} \\log \\alpha - \\frac{\\alpha}{2} w^\\top w + \\frac{n}{2} \\log \\beta - \\frac{\\beta}{2} t^\\top t - \\frac{\\beta}{2} w^\\top \\Phi^\\top \\Phi w + \\beta t^\\top \\Phi w]$  \n",
    "$= \\frac{d}{2} \\log \\alpha - \\frac{\\alpha}{2} (|m_n|^2 + tr(S_n)) + \\frac{n}{2} \\log \\beta - \\frac{\\beta}{2} t^\\top t - \\frac{\\beta}{2} m_n^\\top \\Phi^\\top \\Phi m_n - \\frac{\\beta}{2} tr(\\Phi^\\top \\Phi S_n) + \\beta t^\\top \\Phi m_n$\n",
    "\n",
    "then to maximize $Q$ w.r.t. $\\alpha, \\beta$, take derivatives and set to 0 to get ...\n",
    "\n",
    "$\\alpha = \\frac{d}{|m_n|^2 + tr(S_n)}$  \n",
    "$\\beta^{-1} = \\frac{1}{n} |t - \\Phi m_n|^2 + tr(\\Phi^\\top \\Phi S_n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lemma**\n",
    "\n",
    "note that if $X \\sim \\mathcal{N}(\\mu, \\Sigma)$ ...\n",
    "\n",
    "* $E[X] = \\mu$\n",
    "* $E[X^\\top X] = \\mu^\\top \\mu + tr(\\Sigma)$\n",
    "* $E[X^\\top C X] = \\mu^\\top C \\mu + tr(C \\Sigma)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**theorem**\n",
    "\n",
    "if $Q(\\theta^{new}, \\theta^{old}) > Q(\\theta^{old}, \\theta^{old})$, then $p(y | \\theta^{new}) > p(y | \\theta^{old})$\n",
    "\n",
    "proof\n",
    "\n",
    "* let $Q_{new, old} - Q_{old, old} > 0$\n",
    "* then $E[\\log \\frac{p(Y, Z | \\theta^{new})}{p(Y, Z | \\theta^{old})}]$  \n",
    "$= E[\\log \\frac{p(Y | \\theta^{new})}{p(Y | \\theta^{old})} + \\log \\frac{p(Z | Y, \\theta^{new})}{p(Z | Y, \\theta^{old})}]$  \n",
    "$= \\log \\frac{p(Y | \\theta^{new})}{p(Y | \\theta^{old})} + E[\\log \\frac{p(Z | Y, \\theta^{new})}{p(Z | Y, \\theta^{old})}]$\n",
    "* the second term is less than zero since $\\log$ is concave so the expectation of the log is less than the log of the expectation by Jensen's inequality, and the log of the expectation is just $\\log 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what to do if we cannot compute posterior directly?\n",
    "\n",
    "* so far we've seen\n",
    "    * laplace approximation\n",
    "    * mcmc\n",
    "* alternatively\n",
    "    * variational approximation\n",
    "        * commit to \"type of simple answer\"\n",
    "        * come up with some simplification of the posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational Bayesian Methods\n",
    "\n",
    "let $q(z) \\in$ some family of simple distributions  \n",
    "we want to find the \"best\" such $q(z)$  \n",
    "\"best\": relate $q(z)$ to the true posterior $p(z | y)$  \n",
    "minimize distance between possible $q(z)$ and true $p(z | y)$  \n",
    "e.g., KL divergence\n",
    "\n",
    "given family of distributions $Q$, we want to choose $q = \\arg\\min_Q d_{KL}(q(z) || p(z | y))$\n",
    "\n",
    "but we don't know $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** KL divergence\n",
    "\n",
    "given two densities $p_1$ and $p_2$ with distributions $P_1$ and $P_2$\n",
    "\n",
    "$d_{KL}(P_1 || P_2) = \\int p_1(x) \\log \\frac{p_1(x)}{p_2(x)} dx$\n",
    "\n",
    "**corollary** KL divergence is nonnegative  \n",
    "$-d_{KL}(P_1 || P_2) = \\int p_1(x) \\log \\frac{p_2(x)}{p_1(x)} dx$  \n",
    "$\\leq \\log p_1(x) \\log \\frac{p_2(x)}{p_1(x)}dx$ (Jensen's inequality)  \n",
    "$= \\log 1 = 0$\n",
    "\n",
    "**corollary** KL divergence is not symmetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let $\\log p(y) = L + d_{KL}(q(z) || p(z | y))$  \n",
    "$= \\int q(z) \\log \\frac{p(z , y)}{q(z)} dz + \\int q(z) \\log \\frac{q(z)}{p(z | y)} dz$  \n",
    "$= \\int q(z) \\log \\frac{p(y) p(z | y)}{q(z)} \\frac{q(z)}{p(z | y)} dz$  \n",
    "$= \\int q(z) \\log p(y) dz$  \n",
    "$= \\log p(y)$\n",
    "\n",
    "so $p(y)$ is constant w.r.t. $z$\n",
    "\n",
    "$\\implies$ minimizing KL-divergence is the same as maximizing $L = \\int q(z) \\log \\frac{p(z , y)}{q(z)} dz$ (evidence lower bound, variational lower bound) (ELBO, VLB)\n",
    "\n",
    "since KL-divergence is positive, $L \\leq -\\log p(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L = E_{q(z | \\theta)}[\\log \\frac{p(y, z)}{q(z)}]$  \n",
    "$= E_{q(Z | \\theta)}[\\log p(Y, Z)] - E_{q(Z | \\theta)}[\\log q(Z | \\theta)]$  \n",
    "$= E[\\log \\log p(z)] + E[\\log p(Y | Z)] - E[\\log q(Z)]$  \n",
    "$= E[\\log p(Y | Z)] - d_{KL}(q(z) || p(z))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppose original model has hyperparameters $\\phi$ and $q(z)$ has parameters $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** variational EM algorithm\n",
    "\n",
    "expectation: maximize $L$ w.r.t. $\\theta$  \n",
    "assuming $\\phi$ is fixed, pick best $q(z)$\n",
    "\n",
    "maximization: maximize $L$ w.r.t. $\\phi$  \n",
    "assuming $q$ (and therefore $\\theta$) is fixed, choose best $\\phi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM is a special case of variational EM when $Q$ is not constrained  \n",
    "expectation step picks $q(z) = p(z | y)$  \n",
    "need to plug in new $q(z)$ into $L$ and consider maximization step  \n",
    "so we use $q(z) = p(x | y, \\phi^{old})$  \n",
    "$E_{Z | Y, \\phi^{old}}[\\log p(Y, Z | \\phi^{new}) - E_{Z | Y, \\phi^{old}}[\\log p(Z | Y, \\phi^{old}]$  \n",
    "maximization step is finding $\\phi$ that maximizes the above, and the second term does not depend on $\\phi^{new}$ so we can discard it  \n",
    "so we are left with $Q(\\phi^{new}, \\phi^{old})$ from EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relating to variational autoencoders\n",
    "\n",
    "$\\sum \\log p(y_i) \\geq \\sum_i E_{q(Z_i)} [\\log p(Z_i | Y_i)] - d_{KL}(q(z_i), p(z_i))$\n",
    "\n",
    "$q(z_i)$ implicitly depends on $y_i$\n",
    "\n",
    "VAE makes dependence explicit  \n",
    "$q(z_i | y_i, \\theta)$  \n",
    "represented as neural network  \n",
    "also represent $p(y_i | z_i)$ as neural network\n",
    "\n",
    "decoder is now $p(y_i | z_i, W_1)$  \n",
    "encoder is $q(z_i | y_i, W_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Summary\n",
    "\n",
    "* ML as optimization\n",
    "* probability models\n",
    "* bayesian models\n",
    "* model selection\n",
    "* graphical models\n",
    "* deep models\n",
    "* deep models + architecture\n",
    "* deep + bayesian models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
