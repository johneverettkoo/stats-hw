{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dirichlet Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** how to determine number of clusters for a clustering problem\n",
    "\n",
    "* model comparison\n",
    "* evidence maximization\n",
    "    * comparable (equivalent?) to BIC\n",
    "* would be nice to do this as a part of the model fitting \n",
    "    * instead of fitting multiple models and comparing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** dirichlet process\n",
    "\n",
    "$G \\sim DP(\\alpha, H)$ where $\\alpha \\in \\mathbb{R}$ and $H$ is a base measure  \n",
    "iff $\\forall$ partition of the sample space $A_1 \\cup A_2 \\cup \\cdots$, \n",
    "$(G(A_1), G(A_2), ..., G(A_m)) \\sim Dirichlet(\\alpha H(A_1), \\alpha H(A_2), ..., \\alpha H(A_m))$\n",
    "\n",
    "$\\forall$ partition, distribution induced by sampling $G$ and evaluating it on the partition is dirichlet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If we have a DP and we sample $G$ and then sample $\\theta_1, ..., \\theta_n$,  \n",
    "then $G \\mid \\theta_1, ..., \\theta_n$ is a dirichlet process with parameters $\\alpha + n, \\frac{\\alpha}{\\alpha + n} H + \\frac{n}{\\alpha + n} (\\frac{\\sum \\delta_{\\theta_i}}{n})$\n",
    "\n",
    "2. $\\theta_{n+1} \\mid \\theta_1, ..., \\theta_n \\sim \\frac{1}{\\alpha + n} (\\alpha H + \\sum \\delta_{\\theta_i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we draw a $G$ and then a $\\theta \\mid G$, and we have interval $B$, then  \n",
    "$P(\\theta \\in B) = \\int_G \\int_\\theta p(\\theta) p(\\theta | G) I_B(\\theta) dG d\\theta$  \n",
    "$E[I_B(\\theta)] = H(B)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to calculate the posterior  \n",
    "first focus on one partition $A_1 \\cup \\cdots \\cup A_r$\n",
    "\n",
    "let $(G(A_1), ..., G(A_r)) = (g_1, ..., g_r)$ and $(H(A_1), ..., H(A_r)) = (h_1, ..., h_r)$\n",
    "\n",
    "prior: $p(g) = Dirichlet(\\alpha h)$\n",
    "\n",
    "* $\\propto \\prod_k g_k^{\\alpha h_k - 1}$\n",
    "\n",
    "likelihood: $p(\\theta | g) = \\prod_i g_i^{n_i}$\n",
    "\n",
    "posterior: $\\propto \\prod_k g_k^{\\alpha h_k + n_k - 1}$  \n",
    "$\\implies Dirichlet(\\alpha h + n)$\n",
    "\n",
    "$n = (n_1, ..., n_r)$ and $n_k$ is the number of samples that fall in partition $A_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let $\\alpha^{new} = \\alpha + n$ and $H^{new} = \\frac{\\alpha}{\\alpha + n} H + \\frac{n}{\\alpha + n} (\\frac{\\sum \\delta_{\\theta_i}}{n})$\n",
    "\n",
    "consider new partition over the same space $B_1 \\cup \\cdots \\cup B_s$\n",
    "\n",
    "$H^{new}(B_j) = \\frac{\\alpha}{\\alpha+n} H(B_j) + \\frac{1}{\\alpha + n} \\sum_i I_{B_j}(\\theta_i)$  \n",
    "the second term is just $n_j$\n",
    "\n",
    "then sampling from posterior $DP(\\alpha^{new}, H^{new})$  \n",
    "induced samples over $\\{B_j\\}$ have distribution $Dirichlet(\\alpha^{new} h^{new} + n(B))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to evaluate $\\theta_{n+1} \\mid \\theta_1, ..., \\theta_n \\sim \\frac{1}{\\alpha + n} (\\alpha H + \\sum \\delta_{\\theta_i})$\n",
    "\n",
    "fix partition $B$  \n",
    "then $P(\\theta \\in B_j) = H^{new} (B_j) = \\frac{\\alpha}{\\alpha + n} H*B_j) + \\frac{1}{\\alpha + n} \\sum_i I_{B_j}(\\theta_i)$\n",
    "\n",
    "1. $n \\to \\infty$ then sampling concentrates on a discrete set\n",
    "2. CRP $\\theta_{n+1} \\mid \\theta_1, ..., \\theta_n \\sim \\frac{1}{\\alpha + n} (\\alpha H + \\sum_i \\delta_{\\theta_i})$ (Blackwell-McQueen)\n",
    "    * for each $i$, $z_i = \\begin{cases} k & \\text{w.p. } \\frac{n_k}{\\alpha + n} \\\\ r + 1 & \\text{w.p. } \\frac{\\alpha}{\\alpha + n} \\end{cases}$  \n",
    "    $n_k = $ count of $\\theta_k$  \n",
    "    $k$ ranges from 1 to $r$  \n",
    "    choose new cluster with probability $\\alpha / (\\alpha + n)$ or choose existing cluster with probability proportional to cluster sizes\n",
    "3. given sample $\\theta_1, ..., \\theta_n$ which is size $n$ and infinite number of possible clusters,  \n",
    "$E[\\sum_i^n X_i] = \\sum_i^n E[X_i] = \\sum_i \\frac{\\alpha}{\\alpha + i - 1} \\leq \\alpha \\sum_i i^{-1} = \\alpha O(\\log n)$  \n",
    "proportional to $\\log n$ (similar to BIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DP mixture models\n",
    "\n",
    "$G \\sim DP$  \n",
    "$\\theta_i \\sim G$  \n",
    "$x_i \\sim F(\\theta_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.**\n",
    "\n",
    "$H \\sim \\mathcal{N}(0, 1)$  \n",
    "$X_i \\mid \\theta^*_k \\sim \\mathcal{N}(\\theta^*_k, \\Sigma)$\n",
    "\n",
    "First, initialize $\\theta^*_K$ for $k = 1, 2, ...$ using $H$  \n",
    "Draw $Z_i$ and assign them to one of the $k$ using CRP  \n",
    "Use $\\theta^*_k$ to draw $X_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gibbs sampling**\n",
    "\n",
    "* unobserved: $\\{z_i\\}, \\{\\theta_k^*\\}$\n",
    "* observed: $\\{x_i\\}$\n",
    "* $p(z_i = k \\mid z^{(-i)}, \\{\\theta_k^*\\}, \\{x_i\\})$\n",
    "\n",
    "if $z_i$ goes to an existing cluster, $z_i = k$ w.p. $\\frac{n_k}{\\alpha + n}$  \n",
    "if $z_i$ goes to a new cluster, $z_i = r + 1$ w.p. $\\frac{\\alpha}{\\alpha + n}$\n",
    "\n",
    "also need to consider the likelihood given the cluster  \n",
    "so $p(z_i = k \\mid x_i) \\propto \\frac{n_k}{\\alpha + n} p(x_i \\mid \\theta^*_k)$  \n",
    "$p(z_i = r + 1 \\mid x_i) \\propto \\frac{\\alpha}{\\alpha + n} p(x_i \\mid \\theta_{r+1}^*)$  \n",
    "where $\\theta^*_{r+1} \\sim H$ has to be sampled\n",
    "\n",
    "consider cluster $k$ with parameter $\\theta^*_k$ and $z_{i_1}, z_{i_2}, z_{i_3}$  \n",
    "$\\propto p(\\theta^*_k) \\prod_j p(x_{i_j} | \\theta^*_k)$  \n",
    "and we can calculate all of these terms since we know the prior and likelihood\n",
    "\n",
    "***what is the output of this Gibbs sampling?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**stick breaking construction**\n",
    "\n",
    "equivalent to CRP\n",
    "\n",
    "$\\forall k$, $v_k \\sim Beta(1, \\alpha$  \n",
    "$\\pi_k = v_k \\prod_i^{k-1} (1 - v_i)$, represents class proportions  \n",
    "$\\theta_k^* \\sim H$  \n",
    "$G = \\sum_k^\\infty \\pi_k \\delta_{\\theta^*_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DP mixture of diagonal normal samples\n",
    "\n",
    "$\\forall k$, $v_k \\sim Beta(1, \\alpha)$  \n",
    "$\\pi_k = v_k \\prod_i^{k-1} (1 - v_i)$  \n",
    "$\\mu^*_k \\sim \\mathcal{N}(0, \\sigma_1^2 I)$\n",
    "\n",
    "$\\forall i$, $z_i \\sim Discrete(\\{\\pi\\})$  \n",
    "$x_i \\sim \\mathcal{N}(\\mu^*_{z_i}, \\sigma^2_2, I)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mean field approximation**\n",
    "\n",
    "let $q(\\{v_k\\}, \\{\\mu^*_k\\}, \\{z_i\\}) = (\\prod_k q(v_k)) (\\prod_k q(\\mu^*_k)) (\\prod_i q(z_i))$  \n",
    "enforce truncation in $q(\\cdot)$  \n",
    "for some fixed $T$, $q(v_T = 1) = 1 \\implies q(z_i = k) = 0$ $\\forall k > T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\mu) \\propto (1 - \\mu)^{\\alpha - 1}$\n",
    "\n",
    "$E[\\mu] = \\frac{a}{a + b}$  \n",
    "$E[\\log \\mu] = \\psi(a) - \\psi(b)$  \n",
    "$E[\\log (1 - \\mu) = \\psi(b) - \\psi(a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean field variational solution for $v_s$\n",
    "\n",
    "generic mean field construction:  \n",
    "$E_{q(v_{-s}, \\mu_k, z_i)}[\\log L]$\n",
    "\n",
    "$v_s \\sim Beta(1, \\alpha) \\implies p(v_s) \\propto (1 - v_s)^{\\alpha - 1}$\n",
    "\n",
    "$z_i \\sim Discrete(\\pi) \\implies p(z_i) = \\prod_k \\pi_k^{z_{ik}}$  \n",
    "$= \\prod_k (1 - v_k)^{I(z_i > k)} v_k^{I(z_i = k)}$  \n",
    "\n",
    "$g(v_s) = E[(\\alpha-1) \\log (1 - v_s) \\sum_i (I(z_i > s) \\log (1 - v_s) + I(z_i = s) \\log v_s)]$  \n",
    "let $q(z_i) = \\prod_k \\gamma_{ik}^{z_{ik}}$ where $\\gamma_{ik}$ are parameters  \n",
    "then $g(v_s) = (\\alpha - 1) \\log (1 - v_s) + \\log (1 - v_s) (\\sum_i \\sum_{k=s+1}^T \\gamma_{ik}) + \\log v_s \\sum_i \\gamma_{is}$  \n",
    "then $q(v_s) \\propto v_s^{\\sum_i \\gamma_{is}} (1 - v_s)^{\\alpha + \\sum_i \\sum_k \\gamma_{ik} - 1}$  \n",
    "$\\implies q(v_s) = Beta(v_s \\mid 1 + \\sum_i \\gamma_{is}, \\alpha + \\sum_i, k \\gamma_{ik})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
