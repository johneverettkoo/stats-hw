{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAC Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall from first lecture\n",
    "\n",
    "* classification problems  \n",
    "$loss = \\begin{cases} 1 & \\text{prediction is wrong} \\\\ 0 & \\text{else} \\end{cases}$\n",
    "\n",
    "* class of hyp/predictors $H$\n",
    "\n",
    "* distribution $D$ over $(x_i, t_i)$  \n",
    "$t_i \\in \\{-, +\\}$\n",
    "\n",
    "* realizability  \n",
    "$\\exists h \\in H$ s.t. $L_D(h) = E_{(x, y) \\in D}[h(x) \\neq y] = 0$\n",
    "\n",
    "* sample $s \\sim D^{(m)}$, i.e., iid from $D$\n",
    "\n",
    "**theorem** (imprecise statement)  \n",
    "if sample size $m$ is large enough,  \n",
    "then w.p. $1 - \\delta$, $L_D(ERM(s)) \\leq \\epsilon$\n",
    "\n",
    "ERM outputs $h \\in H$ with minimum training error  \n",
    "in our case, outputs $h$ with zero error due to realizability assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning intervals\n",
    "\n",
    "### min interval (naive/imprecise statement)\n",
    "\n",
    "* given $X_i \\sim D$ on the real line (maybe iid required?)\n",
    "* $t_i = f(x_i)$ such that $t_i \\in \\{-1, 1\\}$\n",
    "* all $+$ examples are within some interval, all $-$ examples are outside the interval\n",
    "* then the min interval is $[a, b]$,  \n",
    "where $a = \\arg\\min_i x_i s.t. t_i = 1$  \n",
    "and $b = \\arg\\max_i x_i s.t. t_i = -1$\n",
    "* note that for some true interval $[c, d]$, $a \\geq c$ and $b \\leq d$\n",
    "* **claim**: if min interval uses \"large enough\" sample size $m$, then w.p. $\\geq 1 - \\delta$, the error of $[a, b]$ is $\\leq \\epsilon$  \n",
    "where the error of the interval is the probability of $X_i$ landing in $[a, b] \\setminus [c, d]$\n",
    "* *proof*\n",
    "    * define $c^+ \\geq c$ such that $P(X \\in [c, c^+]) \\leq \\epsilon / 2$\n",
    "    * define $d^- \\leq d$ s.t. $P(X \\in [d^-, d]) \\leq \\epsilon / 2$\n",
    "    * then $c^+$ and $d^-$ don't actually depend on $a, b$ but only on $c, d$ and $D$\n",
    "    * \"good example\": sample includes at least one point in $[c, c^+]$ and one in $[d^-, d]$  \n",
    "    then $a \\leq c^+$ and $b \\geq d^-$\n",
    "    * then if GE holds, the error of $[a, b]$ is $\\leq \\epsilon$  \n",
    "    $err([a, b]) = P([c, a]) + P([b, d]) \\leq P([c, c^+]) + P([d^-, d]) \\leq \\epsilon$\n",
    "    * then with probability $\\geq 1 - \\delta$, GE holds  \n",
    "    $P($ no samples in $[c, c^+]) \\leq (1 - \\epsilon / 2)^m \\leq e^{-\\epsilon m / 2}$  \n",
    "    we need this to be $\\leq \\delta / 2 \\implies m \\geq \\frac{2}{\\epsilon} \\log \\frac{2}{\\delta}$  \n",
    "    * then if $m(\\epsilon, \\delta)$ is large, GE holds (also similar procedure for upper bound)\n",
    "        * (recall $1 - x \\leq e^{-x}$)\n",
    "* what can we hope for\n",
    "    * if \"true function\" that assigns labels to data is not represented in $H$\n",
    "* e.g., using linear classifier but true is quadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agnostic PAC learning\n",
    "\n",
    "* PAC: \"probably approximately correct\"\n",
    "\n",
    "* algorithm $A$ agnostically PAC learns class $H$ if for any target function labeling, e.g., if $A$ uses $m \\geq (*)$ examples sampled iid from $D$, then with probability $\\geq 1 - \\delta$, $A$ outputs $h$ such that $err(h) \\leq err(h^*) + \\epsilon$ where $h^* = \\arg\\min_{h \\in H} err(h)$\n",
    "    * $(*)$ is some polynomial in $(\\frac{1}{\\delta}, \\frac{1}{\\delta})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **claim**: the ERM algorithm agnostically PAC learns $H$ if $m \\geq (*)$ \n",
    "* note: ERM finds $h \\in H$ which minimizes training set error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chernoff/hoeffding bounds\n",
    "\n",
    "* estimating $p = P(H)$\n",
    "* $\\hat{p} = \\frac{1}{n} \\sum x_i$ where $x_i$ is 1 if heads (0 if tails) from iid\n",
    "* $P(|p - \\hat{p}| > \\alpha) = 2 e^{-2 n \\alpha^2}$\n",
    "\n",
    "* more generally, $X_i \\in [a, b]$ s.t. $E[X_i] = \\mu$\n",
    "    * $\\hat{\\mu} = \\bar{X}_i$\n",
    "    * then $P(|\\mu - \\hat{\\mu}| > \\alpha) \\leq 2 e^{-2 n \\alpha^2 / (b - a)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*proof*\n",
    "\n",
    "* thought to consider: what would guarantee $err(ERM(S)) \\leq err(h^*) + \\epsilon$?\n",
    "    * what we know: ERM picks model with minimum training set error  \n",
    "    $\\hat{err}(h) = \\frac{1}{n} \\sum_i I(h(x_i) \\neq t_i)$, training set error of $h$  \n",
    "    (note that $err(h)$ is the population error of $h$)\n",
    "\n",
    "* \"good event\": $\\forall h \\in H$, $|err(h) - \\hat{err}(h)| \\leq \\epsilon / 2$\n",
    "    * $err(h) = P(h(X) \\neq t)$\n",
    "* lemma 1: if GE holds, then $err(ERM(S)) \\leq err(h^*) + \\epsilon$\n",
    "\n",
    "    * let $\\hat{h} = ERM(S)$\n",
    "    * then $err(\\hat{h}) \\leq \\hat{err}(\\hat{h}) + \\epsilon / 2$ (GE)  \n",
    "    $\\leq \\hat{err}(h^*) + \\epsilon / 2$ (ERM)  \n",
    "    $\\leq err(h^*) + \\epsilon / 2 + \\epsilon / 2$  \n",
    "    $= err(h^*) + \\epsilon$\n",
    "* lemma 2: w.p. $\\geq 1 - \\delta$, $\\forall h \\in H$, $|err(h) - \\hat{err}(h)| \\leq \\epsilon / 2$\n",
    "    * let $e_i = 1$ if $h(x_i) \\neq t_i$ and $0$ otherwise\n",
    "    * $P(e_i = 1) = P(h(X_i) \\neq t_i) = err(h)$\n",
    "    * fix one hypothesis $h$ and take a random sample $S \\sim D^n$  \n",
    "    $P(|err(h) - \\hat{err}(h)| \\geq \\epsilon / 2) \\leq 2 \\exp(-n \\epsilon^2 / 2)$  \n",
    "    we want this to be $\\leq \\delta / |H|$\n",
    "        * to guarantee this, need $n \\epsilon^2 / 2 \\geq \\log \\frac{2 |H|}{\\delta}$  \n",
    "        $\\implies n \\geq \\frac{2}{\\epsilon^2} \\log \\frac{2 |H|}{\\delta}$\n",
    "    * $P(\\text{GE does not occur})$  \n",
    "    $= P(|\\hat{err}(h) - err(h)| > \\epsilon / 2$ $\\forall h \\in H)$  \n",
    "    $\\leq \\sum_h P(|\\hat{err}(h) - err(h)| > \\epsilon / 2)$  \n",
    "    $\\leq \\sum_h \\frac{\\delta}{|H|} = \\delta$\n",
    "    \n",
    "* $P(|err(f(S)) - \\hat{err}(f(S))| \\geq \\epsilon / 2)  \n",
    "realizable case: $P(\\hat{err}(ERM(S)) = 0) = 1$ by definition/assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
