{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAC Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall from first lecture\n",
    "\n",
    "* classification problems  \n",
    "$loss = \\begin{cases} 1 & \\text{prediction is wrong} \\\\ 0 & \\text{else} \\end{cases}$\n",
    "\n",
    "* class of hyp/predictors $H$\n",
    "\n",
    "* distribution $D$ over $(x_i, t_i)$  \n",
    "$t_i \\in \\{-, +\\}$\n",
    "\n",
    "* realizability  \n",
    "$\\exists h \\in H$ s.t. $L_D(h) = E_{(x, y) \\in D}[h(x) \\neq y] = 0$\n",
    "\n",
    "* sample $s \\sim D^{(m)}$, i.e., iid from $D$\n",
    "\n",
    "**theorem** (imprecise statement)  \n",
    "if sample size $m$ is large enough,  \n",
    "then w.p. $1 - \\delta$, $L_D(ERM(s)) \\leq \\epsilon$\n",
    "\n",
    "ERM outputs $h \\in H$ with minimum training error  \n",
    "in our case, outputs $h$ with zero error due to realizability assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learning intervals\n",
    "\n",
    "### min interval (naive/imprecise statement)\n",
    "\n",
    "* given $X_i \\sim D$ on the real line (maybe iid required?)\n",
    "* $t_i = f(x_i)$ such that $t_i \\in \\{-1, 1\\}$\n",
    "* all $+$ examples are within some interval, all $-$ examples are outside the interval\n",
    "* then the min interval is $[a, b]$,  \n",
    "where $a = \\arg\\min_i x_i s.t. t_i = 1$  \n",
    "and $b = \\arg\\max_i x_i s.t. t_i = -1$\n",
    "* note that for some true interval $[c, d]$, $a \\geq c$ and $b \\leq d$\n",
    "* **claim**: if min interval uses \"large enough\" sample size $m$, then w.p. $\\geq 1 - \\delta$, the error of $[a, b]$ is $\\leq \\epsilon$  \n",
    "where the error of the interval is the probability of $X_i$ landing in $[a, b] \\setminus [c, d]$\n",
    "* *proof*\n",
    "    * define $c^+ \\geq c$ such that $P(X \\in [c, c^+]) \\leq \\epsilon / 2$\n",
    "    * define $d^- \\leq d$ s.t. $P(X \\in [d^-, d]) \\leq \\epsilon / 2$\n",
    "    * then $c^+$ and $d^-$ don't actually depend on $a, b$ but only on $c, d$ and $D$\n",
    "    * \"good example\": sample includes at least one point in $[c, c^+]$ and one in $[d^-, d]$  \n",
    "    then $a \\leq c^+$ and $b \\geq d^-$\n",
    "    * then if GE holds, the error of $[a, b]$ is $\\leq \\epsilon$  \n",
    "    $err([a, b]) = P([c, a]) + P([b, d]) \\leq P([c, c^+]) + P([d^-, d]) \\leq \\epsilon$\n",
    "    * then with probability $\\geq 1 - \\delta$, GE holds  \n",
    "    $P($ no samples in $[c, c^+]) \\leq (1 - \\epsilon / 2)^m \\leq e^{-\\epsilon m / 2}$  \n",
    "    we need this to be $\\leq \\delta / 2 \\implies m \\geq \\frac{2}{\\epsilon} \\log \\frac{2}{\\delta}$  \n",
    "    * then if $m(\\epsilon, \\delta)$ is large, GE holds (also similar procedure for upper bound)\n",
    "        * (recall $1 - x \\leq e^{-x}$)\n",
    "* what can we hope for\n",
    "    * if \"true function\" that assigns labels to data is not represented in $H$\n",
    "* e.g., using linear classifier but true is quadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agnostic PAC learning\n",
    "\n",
    "* PAC: \"probably approximately correct\"\n",
    "\n",
    "* algorithm $A$ agnostically PAC learns class $H$ if for any target function labeling, e.g., if $A$ uses $m \\geq f(\\delta, \\epsilon)$ examples sampled iid from $D$, then with probability $\\geq 1 - \\delta$, $A$ outputs $h$ such that $err(h) \\leq err(h^*) + \\epsilon$ where $h^* = \\arg\\min_{h \\in H} err(h)$\n",
    "    * $f(\\delta, \\epsilon)$ is some polynomial in $(\\frac{1}{\\delta}, \\frac{1}{\\epsilon})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**claim**: the ERM algorithm agnostically PAC learns $H$ if $m \\geq (*)$ \n",
    "\n",
    "* note: ERM finds $h \\in H$ which minimizes training set error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chernoff/hoeffding bounds\n",
    "\n",
    "* estimating $p = P(H)$\n",
    "* $\\hat{p} = \\frac{1}{n} \\sum x_i$ where $x_i$ is 1 if heads (0 if tails) from iid\n",
    "* $P(|p - \\hat{p}| > \\alpha) = 2 e^{-2 n \\alpha^2}$\n",
    "\n",
    "* more generally, $X_i \\in [a, b]$ s.t. $E[X_i] = \\mu$\n",
    "    * $\\hat{\\mu} = \\bar{X}_i$\n",
    "    * then $P(|\\mu - \\hat{\\mu}| > \\alpha) \\leq 2 e^{-2 n \\alpha^2 / (b - a)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*proof*\n",
    "\n",
    "* thought to consider: what would guarantee $err(ERM(S)) \\leq err(h^*) + \\epsilon$?\n",
    "    * what we know: ERM picks model with minimum training set error  \n",
    "    $\\hat{err}(h) = \\frac{1}{n} \\sum_i I(h(x_i) \\neq t_i)$, training set error of $h$  \n",
    "    (note that $err(h)$ is the population error of $h$)\n",
    "\n",
    "* \"good event\": $\\forall h \\in H$, $|err(h) - \\hat{err}(h)| \\leq \\epsilon / 2$\n",
    "    * $err(h) = P(h(X) \\neq t)$\n",
    "* lemma 1: if GE holds, then $err(ERM(S)) \\leq err(h^*) + \\epsilon$\n",
    "\n",
    "    * let $\\hat{h} = ERM(S)$\n",
    "    * then $err(\\hat{h}) \\leq \\hat{err}(\\hat{h}) + \\epsilon / 2$ (GE)  \n",
    "    $\\leq \\hat{err}(h^*) + \\epsilon / 2$ (ERM)  \n",
    "    $\\leq err(h^*) + \\epsilon / 2 + \\epsilon / 2$  \n",
    "    $= err(h^*) + \\epsilon$\n",
    "* lemma 2: w.p. $\\geq 1 - \\delta$, $\\forall h \\in H$, $|err(h) - \\hat{err}(h)| \\leq \\epsilon / 2$\n",
    "    * let $e_i = 1$ if $h(x_i) \\neq t_i$ and $0$ otherwise\n",
    "    * $P(e_i = 1) = P(h(X_i) \\neq t_i) = err(h)$\n",
    "    * fix one hypothesis $h$ and take a random sample $S \\sim D^n$  \n",
    "    $P(|err(h) - \\hat{err}(h)| \\geq \\epsilon / 2) \\leq 2 \\exp(-n \\epsilon^2 / 2)$  \n",
    "    we want this to be $\\leq \\delta / |H|$\n",
    "        * to guarantee this, need $n \\epsilon^2 / 2 \\geq \\log \\frac{2 |H|}{\\delta}$  \n",
    "        $\\implies n \\geq \\frac{2}{\\epsilon^2} \\log \\frac{2 |H|}{\\delta}$\n",
    "    * $P(\\text{GE does not occur})$  \n",
    "    $= P(|\\hat{err}(h) - err(h)| > \\epsilon / 2$ $\\forall h \\in H)$  \n",
    "    $\\leq \\sum_h P(|\\hat{err}(h) - err(h)| > \\epsilon / 2)$  \n",
    "    $\\leq \\sum_h \\frac{\\delta}{|H|} = \\delta$\n",
    "    \n",
    "* $P(|err(f(S)) - \\hat{err}(f(S))| \\geq \\epsilon / 2)$  \n",
    "realizable case: $P(\\hat{err}(ERM(S)) = 0) = 1$ by definition/assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from classification to any type of prediction (e.g., regression)\n",
    "\n",
    "recall for (one type of) classification:\n",
    "\n",
    "* $l_{0-1}(t, \\hat{t}) = \\begin{cases} 1 & t \\neq \\hat{t} \\\\ 0 & else \\end{cases}$\n",
    "* $err(h) = E[l_{0, 1}(t, h(x))]$\n",
    "* let $risk(h) = E[l(t, h(x))]$, the expected loss\n",
    "\n",
    "for regression\n",
    "\n",
    "* typically $l_2(t, \\hat{t}) = (t - \\hat{t})^2$\n",
    "* $\\hat{t} = w^\\top x$\n",
    "* $H = \\{w\\}$, the possible choices (domain?) of $w$\n",
    "* $risk(w) = E[l(t, w^\\top x)]$\n",
    "\n",
    "log loss\n",
    "\n",
    "* $l(t, p_w) = -\\log p(t | x, w)$\n",
    "* $risk(w) = E[-\\log p(t | x, w)]$\n",
    "\n",
    "important caveat:  \n",
    "ERM agnostically PAC learns $H$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R(h) = E_{x, t}[l(h, (x, t))]$\n",
    "\n",
    "then $\\hat{R}(h) = N^{-1} \\sum_i l(h, (x_i, t_i))$ (which $\\stackrel{p}{\\to} R(h)$)\n",
    "\n",
    "* lemma 1 is evident from this\n",
    "\n",
    "for lemma 2, use hoeffding inequality\n",
    "\n",
    "* e.g., for square loss\n",
    "    * need to assume $|t_i| \\leq T$ and $||x_i|| \\leq r$ and $||w|| \\leq B$\n",
    "    * then $(t_i - w^\\top x_i)^2 \\leq (T + B r)^2 = B^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### markov's inequality\n",
    "\n",
    "if random variable $X \\geq 0$, then $P(X \\geq a) \\leq \\frac{E[X]}{a}$\n",
    "\n",
    "*proof*  \n",
    "\n",
    "$E[X] = \\int_0^\\infty x p(x) dx$\n",
    "$= \\int_0^a x p(x) dx + \\int_a^\\infty x p(x) dx$  \n",
    "$\\leq \\int_a^\\infty x p(x) dx$\n",
    "$\\leq \\int_a^\\infty a p(x) dx$  \n",
    "$= a P(X \\geq a)$\n",
    "\n",
    "#### chebychev's inequality\n",
    "\n",
    "let $E[Z] = \\mu$ and $Var(Z) = \\sigma^2$  \n",
    "then $P(|Z - \\mu| \\geq a) \\leq \\frac{\\sigma^2}{a^2}$\n",
    "\n",
    "*proof*\n",
    "\n",
    "start with markov's inequality  \n",
    "$P(|Z - \\mu| \\geq a) = P((Z - \\mu)^2 \\geq a^2)$\n",
    "$\\leq \\frac{E[(Z - \\mu)^2]}{a^2}$\n",
    "$= \\sigma^2 / a^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using chebychev's inequality to estimate the mean\n",
    "\n",
    "let $\\bar{X}$ be the sample mean of iid random variables with $E[X_i] = \\mu$ and $Var(X_i) = \\sigma^2$\n",
    "\n",
    "then $E[\\bar{X}] = \\mu$  \n",
    "and $Var(\\bar{X}) = \\sigma^2 / n$\n",
    "\n",
    "$P(|\\bar{X} - \\mu| > a) = \\frac{\\sigma^2}{n a^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hoeffding's inequality: if $X \\in [a, b]$, then \n",
    "$P(|\\bar{X} - \\mu| > \\alpha) \\leq 2 e^{-\\frac{2 n \\alpha^2}{(b - a)^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chernoff: $P(|p - \\hat{p}| > \\alpha) \\leq 2 e^{-2 n \\alpha^2}$\n",
    "\n",
    "hoeffding: $P(|\\bar{X} - \\mu| > \\alpha) \\leq 2 e^{-\\frac{2 n \\alpha^2}{(b - a)^2}}$\n",
    "\n",
    "**e.g.** markov vs chernoff\n",
    "\n",
    "given \n",
    "\n",
    "* coin with $P(H) = .25$\n",
    "* $n = 200$\n",
    "* $\\hat{p} = n^{-1} \\sum_i X_i$\n",
    "\n",
    "solve for an upper bound for $P(\\hat{p} \\geq .5)$\n",
    "\n",
    "* markov: $E[X] / a = .25 / .5 = .5$\n",
    "* chernoff: this is equivalent to $P(|p - \\hat{p}| > .25) \\leq 2 e^{-2 (200) (.0625)} \\approx 3 \\times 10^{-11}$\n",
    "* can also use chebychev (upper bound of $.015$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.** \n",
    "\n",
    "given two coins $p_1 = .25$, $p_2 = .5$\n",
    "\n",
    "want to identify which coin has $p = .25$\n",
    "\n",
    "one method: pick one coin, flip $n$ times, and if $\\hat{p} \\leq .375$, then it is coin 1, else it's coin 2\n",
    "\n",
    "claim: $\\forall \\delta > 0$, $\\exists N$ s.t. $n > N \\implies$ we pick the correct coin w.p. $1 - \\delta$\n",
    "\n",
    "*proof*  \n",
    "in either case, if we make the wrong choice, $|p - \\hat{p} \\geq .125$  \n",
    "$P(|p - \\hat{p} \\geq .125) \\leq 2 e^{-2 n (.125)^2} \\leq \\delta$  \n",
    "$\\implies n \\geq 32 \\log \\frac{2}{\\delta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.**\n",
    "\n",
    "given two coins with $p_1 = .25$ and unknown $p_2$\n",
    "\n",
    "want to identify coin with $P(H) \\leq .25$ (coin 1 is this, coin 2 could be this)\n",
    "\n",
    "no guarantee without knowing what $|p_1 - p_2|$ is (or characterizing it in some way)\n",
    "\n",
    "**e.g.**\n",
    "\n",
    "given two coins $p_1 = .25$, $p_2$ unknown\n",
    "\n",
    "goal: identify coin with $P(H) \\leq .375$\n",
    "\n",
    "method/algorithm: \n",
    "\n",
    "* if $p_2 < .25$, then flip both coins $n$ times and choose one with smaller $\\hat{p}$, guaranteed to choose a correct answer\n",
    "* if $p_2 \\in [.25, .375]$, same method as in previous case, guaranteed to choose a correct answer\n",
    "* if $p_2 > .375$, not guaranteed to choose correct answer if $\\hat{p}_1 > \\hat{p}_2$\n",
    "    * happens when at least one estimate is off by $\\geq (.375 - .25) / 2 = .0625$\n",
    "    * need $P(|p_1 - \\hat{p}_1| \\geq .0625) \\leq \\delta / 2$ and $P(|p_2 - \\hat{p}| \\geq .0625) \\leq \\delta / 2$\n",
    "    * $e^{-2 n (.0625)^2} \\leq \\delta / 2 \\implies n \\geq 128 \\log \\frac{2}{\\delta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remark**: we require $n \\propto \\epsilon^{-2}$ and $n \\propto -\\log \\delta$ for this to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e.g.**\n",
    "\n",
    "given\n",
    "\n",
    "* $k$ coins\n",
    "* known: $p_1 \\leq \\alpha$\n",
    "* unknown: everything else about the other coins\n",
    "\n",
    "goal: find coin s.t. $p_i \\leq 2 \\alpha$\n",
    "\n",
    "algorithm: \n",
    "\n",
    "* flip each coin $n$ times\n",
    "* pick coin $i = \\min_i \\hat{p}_i$\n",
    "\n",
    "claim: if $n \\geq \\frac{2}{\\alpha^2} \\log \\frac{2 k}{\\delta}$, then w.p. $\\geq 1 - \\delta$, we choose coin that satisfies the goal\n",
    "\n",
    "*proof*\n",
    "\n",
    "* lemma 1: if $\\forall i$, $|p_i - \\hat{p}_i| \\leq \\alpha / 2$, then the algorithm picks $i$ s.t. $p_i \\leq 2 \\alpha$  \n",
    "let $j$ be any coin s.t. $p_j > 2 \\alpha$  \n",
    "$\\hat{p}_j \\geq p_j - \\alpha / 2 > \\alpha + \\alpha / 2$  \n",
    "$\\hat{p}_1 \\geq p_1 + \\alpha / 2 = \\frac{3}{2} \\alpha$  \n",
    "$\\hat{p}_1 < \\hat{p}_j$  \n",
    "so we do not pick $j$\n",
    "* lemma 2: w.p. $\\leq 1 - \\delta$, $\\forall i$, $|p_i - \\hat{p}_i| \\leq \\alpha / 2$  \n",
    "$P(|\\hat{p}_i - p_i| > \\alpha / 2) \\leq 2 \\exp(-2 n \\alpha^2 / 4)$  \n",
    "$n \\geq \\frac{2}{\\alpha^2} \\log \\frac{2 k}{\\delta} \\leq \\delta / k$  \n",
    "$P( \\exists i$ s.t. $(|\\cdot| > \\alpha / 2) \\leq k \\delta / 2k = \\delta$  \n",
    "$2 \\exp(-2 n \\alpha^2 / 4) \\leq \\cdots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*proof of Hoeffding's bound*\n",
    "\n",
    "statement: $P(|\\mu - \\hat{\\mu}| > \\alpha) \\leq 2 e^{-2 n \\alpha^2 / (b - a)^2}$\n",
    "\n",
    "we will consider $x_i \\in [0, 1]$\n",
    "\n",
    "consider $P(\\hat{\\mu} \\geq \\mu + \\alpha)$\n",
    "\n",
    "claim: $\\hat{\\mu} \\geq \\mu + \\alpha \\iff e^{\\hat{\\mu}} > e^{\\mu + \\alpha}$\n",
    "$\\iff e^{n h \\hat{\\mu}} \\geq e^{n h (\\hat{\\mu} + \\alpha)}$\n",
    "\n",
    "$P(e^{n h \\hat{\\mu}} \\geq e^{n h (\\mu + \\alpha)}) \\leq \\frac{E[e^{n h \\hat{\\mu}}]}{e^{n h (\\mu + \\alpha)}}$\n",
    "$= e^{-n h \\mu - n h \\alpha} E[e^{h \\sum x_i}]$  \n",
    "$= e^{n h \\mu - n h \\alpha} E[e^{\\sum h x_i}]$  \n",
    "$= e^{n h \\mu - n h \\alpha} \\prod E[e^{h x_i}]$  \n",
    "$\\leq e^{-n h \\mu - n h \\alpha} \\prod E[1 - x_i + x_i e^h]$  \n",
    "$= e^{-n h \\mu - n h \\alpha} (1 - \\mu + \\mu e^h)^n$  \n",
    "$= e^{-n h \\mu - n h \\alpha + n \\log (1 - \\mu + \\mu e^h)}$  \n",
    "$= e^{-n h \\alpha + n (-h \\mu + \\log (1 - \\mu + \\mu e^h))}$\n",
    "\n",
    "we can show that the part in the parentheses is $L(\\mu, h) \\leq h^2 / 8$  \n",
    "$L(\\mu, h) = -h \\mu + \\log (1 - \\mu + \\mu e^h)$  \n",
    "$L(\\mu, 0) = 0$, $L'(\\mu, 0) = 0$, $L''(\\mu, h) \\leq 1 / 4$\n",
    "\n",
    "and we get $\\cdots \\leq e^{-n h \\alpha + n h^2 / 8}$  \n",
    "letting $h = 4 \\alpha$, we get  \n",
    "$e^{-n 4 \\alpha^2 + n (16 \\alpha^2) / 8}$  \n",
    "$= e^{-2 n \\alpha^2}$\n",
    "\n",
    "similar proof for $P(\\hat{\\mu} < \\mu - \\alpha) \\leq e^{-2 n \\alpha^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAC: $\\forall D$, $\\forall \\epsilon$, $\\forall \\delta$, algorithm runs in time/sample $O(\\epsilon^{-a} \\delta^{-b})$ w.p. $\\geq 1 - \\delta$ outputs $h$ s.t. $E[l(h, (x, t))] \\leq E[l(h^*, (x, t))] + \\epsilon$ where $h^* = \\arg\\min E[l(h, (x, t))]$, the optimal solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def: \"perhaps PAC learnable\": $\\delta = 1/2$, arbitrary $D$ and $\\epsilon$\n",
    "\n",
    "claim: if $H$ is perhaps PAC learnable, then $H$ is PAC learnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alternatively, relax the claim on $\\epsilon$ and focus on $\\forall D$, $\\forall \\delta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "claim: if $H$ is weakly PAC learnable, then $H$ is PAC learnable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
