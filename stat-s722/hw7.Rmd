---
title: 'S722 HW7'
author: 'John Koo'
output: pdf_document
# output: html_document
# geometry: "left=1cm,right=1cm,top=1cm,bottom=1.5cm"
urlcolor: blue
header-includes:
- \usepackage{float}
- \usepackage{mathtools}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.pos = 'H', 
                      fig.align = 'center', 
                      fig.height = 2, 
                      fig.width = 4, 
                      fig.dpi = 300)
options(xtable.comment = FALSE, 
        xtable.table.placement = 'H')
```

To save on typing, I will denote 
$\frac{\partial^k}{\partial x^k} f(x) = \partial_x^k f(x)$.

# 4.20

## a

$Y_1 = X_1^2 + X_2^2$  
$Y_2 = \frac{X_1}{\sqrt{Y_1}}$

$\implies X_1 = Y_1^{1/2} Y_2$  
and $X_2 = \sqrt{Y_1 - Y_1 Y_2^2}$

$\partial_{Y_1} X_1 = \frac{1}{2} Y_1^{-1/2} Y_2$  $
$\partial_{Y_2} X_1 = Y_1^{1/2}$  
$\partial_{Y_1} X_2 = \frac{1}{2} \sqrt{\frac{1 - Y_2^2}{Y_1}}$  
$\partial_{Y_2} X_2 = \frac{Y_2 Y_1^{1/2}}{\sqrt{1 - Y_2^2}}$

Then $|J| = 
\frac{1}{2} \frac{Y_2^2}{\sqrt{1 - Y_2^2}} - \frac{1}{2} \sqrt{1 - Y^2}$
$= \frac{1}{2 \sqrt{1 - Y_2^2}}$

Since the density functions for $X_1$ and $X_2$ are unimodal and symmetric, we 
just multiply this by 2. 

Then we get
$f(y_1, y_2) = 
(2 \pi \sigma^2)^{-1} e^{-\frac{y_1}{2 \sigma^2}} (1 - y_2^2)^{-1/2}$

## b

Let $f_{Y_1}(y_1) \propto e^{-\frac{y_1}{2 \sigma^2}}$ and 
$f_{Y_2}(y_2) \propto (1 - y_2^2)^{-1/2}$. Then we can see that 
$f(y_1, y_2) = f_{Y_1}(y_1) f_{Y_2}(y_2)$.

If we use polar coordinates, we can see that $Y_1 = R^2$ and $Y_2 = cos \theta$,
and so $Y_1$ and $Y_2$ do not share any terms.

# 4.24

We can see that $Z_2 = X / Z_1$, so $X = Z_1 Z_2$. Then $Y = Z_1 (1 - Z_2)$.

$\partial_{Z_1} X = Z_2$  
$\partial_{Z_2} X = Z_1$  
$\partial_{Z_1} Y = 1 - Z_2$  
$\partial_{Z_2} Y = -Z_1$

$\implies |J| = |-Z_1 Z_2 - Z_1 (1 - Z_2)| = Z_1$

Then $f(z_1, z_2) \propto 
(z_1 z_2)^{r-1} e^{-z_1 z_2} (z_1 - z_1 z_2)^{s-1} e^{-z_1 + z_1 z_2} z_1$  
$= z_1^{r+s-1} e^{-z_1} \times z_2^{r-1} (1 - z_2)^{s-1}$

And we can identify the product of the kernels of the gamma and beta densities. 

$Z_1 \sim Gamma(r + s, 1)$  
$Z_2 \sim Beta(r, s)$

# 4.26

## a

$P(Z \leq z, W = 0) = P(\min(X, Y) \leq z, Y \leq X) = P(Y \leq z, Y \leq X)$  
$= \int_0^z \int_y^\infty \lambda^{-1} e^{-x / \lambda} \mu^{-1} e^{-y / \mu} 
dx dy$  
$= \frac{\lambda}{\mu + \lambda} (1 - e^{-(\mu^{-1} + \lambda^{-1}) z})$

And similarly, $P(Z \leq z, W = 1) = 
\frac{\mu}{\mu + \lambda} (1 - e^{-(\mu^{-1} + \lambda^{-1}) z})$

## b

So we can say $P(Z \leq z, W = w) = 
\frac{\mu w + (1 - w) \lambda}{\mu + \lambda} \times
(1 - e^{-(\mu^{-1} + \lambda^{-1}) z})$

and we can see that this is separable. 

# 4.27

$U = X + Y$  
$V = X - Y$

$\implies U + V = 2X \implies X = \frac{U+V}{2}$ and $Y = \frac{U-V}{2}$

$\partial_U X = 1/2$  
$\partial_V X = 1/2$  
$\partial_U Y = 1/2$  
$\partial_V Y = -1/2$

$|J| = |-1/4 - 1/4| = 1/2$

$f(u, v) \propto
e^{-\frac{1}{2 \sigma^2} ((\frac{u+v}{2} - \mu)^2 + 
(\frac{u-v}{2} - \gamma)^2)}$  
$\propto e^{-\frac{1}{2 \sigma^2} (u^2 / 4 + uv + v^2 / 2 - \mu u - \mu v + 
u^2 / 4 - uv + v^2 / 4 - \gamma u - \gamma v)}$  
$= e^{-\frac{1}{2 \sigma^2} (u^2 / 4 + v^2 / 2 - \mu u - \mu v + u^2 / 4 + 
v^2 / 4 - \gamma u - \gamma v)}$ 

and we can see that $u$ and $v$ are separable since there are no mixed terms. 

# 4.31

## a

$E[Y] = E[E[Y|X]] = E[nX] = n E[X] = n/2$

$Var(Y) = Var(E[Y|X]) + E[Var(Y|X)]$
$= Var(n X) + E[n X (1 - X)]$
$= n^2 / 12 + n (E[X] - E[X^2])$
$= n^2 / 12 + n(1/2 - 1/12 - 1/4) = n^2 / 12 + n / 6$

## b

$f(x, y) = f(y|x) f(x) = \binom{n}{y} x^y (1-x)^{n-y} I(0 < x < 1)$

## c

$f(y) = \int_0^1 \binom{n}{y} x^y (1-x)^{n-y} dx$
$= \binom{n}{y} \int_0^1 x^{y+1-1} (1-x)^{n-y+1-1} dx$
$= \binom{n}{y} B(y + 1, n - y + 1)$

# 4.44

$E[X_1 + \cdots + X_n] = E[X_1] + \cdots + E[X_n] = \mu_1 + \cdots + \mu_n$

$Var(X_1 + \cdots + X_n) = E[(X_1 + \cdots + X_n - \mu_1 - \cdots - \mu_n)^2]$  
$= E[(\sum_i^n X_i - \mu_i)^2]$  
$= E[\sum_i^n (X_i - \mu_i)^2 + 2 \sum_{i \neq j} (X_i - \mu_i) (X_j - \mu_j)]$
$= \sum_i E[(X_i - \mu_i)^2] + 2 \sum_{i \neq j} E[(X_i - \mu_i) (X_j - \mu_j)]$  
$= \sum_i Var(X_i) + 2 \sum_{i \neq j} Cov(X_i, X_j)$

# 4.45

## a

Let $u = \frac{x - \mu_X}{\sigma_X}$ and $v = \frac{y - \mu_Y}{\sigma_Y}$. 
Then $f_{XY}(u, v) \propto 
\exp^{-\frac{1}{2 (1 - \rho^2)} (u^2 - 2 \rho u v + v^2)}$  
$\implies f_X(x) \propto 
\int \exp^{-\frac{1}{2 (1 - \rho^2)} (u^2 - 2 \rho u v + v^2)} dy$  
$= \int \exp^{-\frac{1}{2 (1 - \rho^2)} 
(u^2 - 2 \rho u v + v^2 - \rho^2 u^2 - \rho^2 u^2)} dy$  
$= \int \exp^{-\frac{1}{2 (1 - \rho^2)} 
((v - \rho u)^2 + (1 - \rho^2) u^2)} dy$  
$= \exp^{-u^2 / 2} \int \exp^{-\frac{1}{2 (1 - \rho^2)} (v - \rho u)^2} dy$  
$\propto \exp^{-u^2 / 2} = \exp^{-\frac{(x - \mu_X)^2}{2 \sigma_X^2}}$  
$\implies X \sim \mathcal{N}(\mu_X, \sigma_X^2)$

and by symmetry, $Y \sim \mathcal{N}(\mu_Y, \sigma_Y^2)$

## b

$f_{Y|X}(y) \propto \exp \bigg(
  -\frac{1}{2 (1 - \rho^2)} \big(
    (\frac{x - \mu_X}{\sigma_X})^2 - 
    2 \rho\frac{x - \mu_X}{\sigma_X} \frac{y - \mu_Y}{\sigma_Y} + 
    (\frac{y - \mu_Y}{\sigma_Y})^2 
  \big) + 
  \frac{1}{2} (\frac{x - \mu_X}{\sigma_X})^2
\bigg)$  
$\propto \exp \bigg(
  -\frac{1}{2 \sigma_Y^2 (1 - \rho^2)} 
  (y^2 - 2 \mu_Y y - 2 \rho \frac{\sigma_Y}{\sigma_X} (xy - \mu_X y) )
\bigg)$  
$= \exp \bigg( 
  -\frac{1}{2 \sigma_Y^2 (1 - \rho^2)} 
  (y^2 - 2 (\mu_Y + \rho \frac{\sigma_Y}{\sigma_X} (x - \mu_x)))
\bigg)$  
$\propto \exp \bigg( 
  -\frac{1}{2 \sigma_Y^2 (1 - \rho^2)} 
  \big(y - (\mu_Y + \rho \frac{\sigma_Y}{\sigma_X} (x - \mu_X))\big)^2 
\bigg)$  
$\implies Y \mid x \sim 
\mathcal{N} \bigg(\mu_Y + \rho \frac{\sigma_Y}{\sigma_X} (x - \mu_X), 
  \sigma_Y^2 (1 - \rho^2)
\bigg)$
  
## c

We know that $aX + bY$ is normally distributed since linear transformations of 
normals are normal.

$E[aX + bY] = a E[X] + b E[Y] = a \mu_X + b \mu_Y$

$Var(aX + bY) = a^2 \sigma_X^2 + b^2 \sigma_Y^2 + 2 a b Cov(X, Y)$
$= a^2 \sigma_X^2 + b^2 \sigma_Y^2 + 2 a b \rho \sigma_X \sigma_Y$

# 4.46

## a

$E[X] = a_X E[Z_1] + b_X E[Z_2] + c_X = c_X$  
$Var(X) = a_X^2 Var(Z_1) + b_X^2 Var(Z_2) = a_X^2 + b_X^2$

Similarly, $E[Y] = c_Y$ and $Var(Y) = a_Y^2 + b_Y^2$

$Cov(X, Y) = \frac{1}{2} (Var(X + Y) - Var(X) - Var(Y))$  
$= \frac{1}{2} (a_X^2 + 2 a_X a_Y + a_Y^2 + 
b_X^2 + 2 b_X b_Y + bY^2 - a_X^2 - a_Y^2 - b_X^2 - b_Y^2)$
$= a_X a_Y + b_X b_Y$

## b

$E[X] = c_X = \mu_X$  
$Var(X) = \frac{1 + \rho}{2} \sigma_X^2 + \frac{1 - \rho}{2} \sigma_X^2$
$= \sigma_X^2$

Similarly, $E[Y] = \mu_Y$ and $Var(Y) = \sigma_Y^2$

$Cov(X, Y) = 
\frac{1 + \rho}{2} \sigma_X \sigma_Y - \frac{1 - \rho}{2} \sigma_X \sigma_Y$
$= \rho \sigma_X \sigma_Y$  
$\implies Cor(X, Y) = Cov(X, Y) / (\sigma_X \sigma_Y) = \rho$

## c

After some algebra ...

$Z_1 = 
\frac{\frac{X - \mu_X}{\sigma_X} + \frac{Y - \mu_Y}{\sigma_Y}}
{\sqrt{2 (1 + \rho)}}$

$Z_2 =
\frac{\frac{X - \mu_X}{\sigma_X} + \frac{Y - \mu_Y}{\sigma_Y}}
{\sqrt{2 (1 - \rho)}}$

... and additionally ...

$|J| = \frac{1}{\sigma_X \sigma_Y \sqrt{1 - \rho^2}}$

Then $f_{XY}(x, y) \propto \exp \bigg( 
  -\frac{1}{2 (1 - \rho^2)} \big( 
    (\frac{x - \mu_X}{\sigma_X})^2 + (\frac{y - \mu_Y}{\sigma_Y})^2 - 
    2 \rho \frac{x - \mu_X}{\sigma_X} \frac{y - \mu_Y}{\sigma_Y} 
  \big) 
\bigg)$

## d

Since we have 5 equations for 6 variables, there are an infinite number of
solutions. 

# 4.50

We know that $E[X] = E[Y] = 0$ and $Var(X) = Var(Y) = 1$  
$\implies E[X^2] = E[Y^2] = 1$

$Cov(X, Y) = E[XY] - E[X] E[Y] = E[XY]$
$= \int x y f(x, y) dx dy$  
$= \int x y f(y|x) f(x) dx dy$  
$= \int x f(x) dx \int y f(y|x) dy$  
$= \int x f(x) \rho x dx$  
$= \rho \int x^2 f(x) = \rho E[X^2] = \rho$

Then $Cor(X, Y) = Cov(X, Y) / \sqrt{Var(X) Var(Y)} = Cov(X, Y) = \rho$

$Cov(X^2, Y^2) = E[X^2 Y^2] -E[X^2] E[Y^2] = E[X^2 Y^2] - 1$

$E[X^2 Y^2] = \int x^2 y^2 f(y|x) f(x) dy dx$  
$= \int x^2 f(x) dx \int y^2 f(y|x) dy$  
$= \int x^2 f(x) E[Y^2 | x] dx$  
$= \int x^2 f(x) (Var(Y | x) + (E[Y| x])^2) dx$  $
$= \int x^2 f(x) (1 - \rho^2 + \rho^2 x^2) dx$  
$= \int x^2 f(x) dx - \rho^2 \int x^2 f(x) dx + \rho^2 \int x^4 f(x) dx$  
$= E[X^2] - \rho^2 E[X^2] + \rho^2 E[X^4]$  
$= 1 - \rho^2 + 3 \rho^2 = 2 \rho^2 + 1$  
$\implies E[X^2 Y^2] = 2 \rho^2 + 1 - 1 = 2 \rho^2$

$Var(X^2) = E[X^4] - (E[X^2])^2 = 3 - 1 = 2$

$\implies Cor(X^2, Y^2) = \frac{2 \rho^2}{\sqrt{2 \times 2}} = \rho^2$

# 5.10

## a

$\theta_1 = E[X_i] = \mu$  
$\theta_2 = E[(X_i - \mu)^2] - \sigma^2$  
$\theta_2 = E[(X_i - \mu)^3] = 0$ since odd central moments of normally distributed variables are 0  
$\theta_4 = E[(X_i - \mu)^4] = 3 \sigma^4$ (from S620 notes)

## b

$Var(S^2) = \frac{1}{n} (\theta_4 - \frac{n-3}{n-1} \theta_2^2)$  
$= \frac{1}{n} (3 \sigma^4 - \frac{n-3}{n-1} \sigma^4) = \frac{2 \sigma^4}{n-1}$

## c

Let $\Sigma \sim \chi^2_{n-1}$. Then $Var(\Sigma) = 2 (n-1)$.

$S^2 = \sigma^2 \Sigma / (n-1)$  
$\implies Var(S^2) = \frac{\sigma^4}{(n-1)^2} Var(\Sigma)$  
$= \frac{\sigma^4}{(n-1)} 2 (n-1) = \frac{2 \sigma^4}{n-1}$

# 5.14

## a

Suppose $Cov(\sum a_{ij} X_j, \sum b_{rj} X_j) = 0$.

This is also equal to
$E[(\sum a_{ij} X_j) (\sum b_{rj} X_j)] - E[\sum a_{ij} X_j] E[\sum b_{rj} X_j]$

Then 
$E[(\sum a_{ij} X_j) (\sum b_{rj} X_j)] = E[\sum a_{ij} X_j] E[\sum b_{rj} X_j]$
$\implies \sum a_{ij} X_j$ and $\sum b_{rj} X_j$ are independent.

## b

$Cov(\sum a_{ij} X_j, \sum b_{rj} X_j)$
$= E[(\sum a_{ij} (X_j - \mu_j)) (\sum b_{rj} (X_j - \mu_j))]$  
$= E[\sum a_{ij} b_{rj} \sigma_j^2 Z_j]$  
$= \sum a_{ij} b_{rj} \sigma_j^2$

# 5.18

## a

$E[X] = E[Z] \frac{1}{p} E[\Sigma^{-1/2}]$ where $Z \sim \mathcal{N}(0, 1)$ and 
$\Sigma \sim \chi^2_p$ and they are independent. $E[Z] = 0$, so the entire 
expression is 0.

## b

$Z^2 \sim \chi^2_1$, so $X^2 = Z^2 / (\Sigma / p)$ 
$= (Z^2 / 1) / (\Sigma / p) \sim F_{1, p}$

## c

$f(x) = \frac{\Gamma(\frac{p+1}{2})}{\Gamma(p/2) \sqrt{p \pi}} 
(1 + x^2 / p)^{-(p+1) / 2}$

By Stirling's approximation ...

* $\Gamma(\frac{p+1}{2}) \to (2 \pi \frac{p-1}{2})^{1/2}
(\frac{p-1}{2})^{\frac{p-1}{2}} e^{-\frac{p-1}{2}}$
* $\Gamma(p/2) \to (2 \pi \frac{p-2}{2})^{1/2} (\frac{p-2}{2})^{\frac{p-2}{2}}
e^{-\frac{p-2}{2}}$

Dividing the two and letting $p-1 \approx p-2$, we are left with $2^{-1/2}$.

And $(1 + x^2 / p)^{-\frac{p+1}{2}} \to e^{-x^2 / 2}$

So the expression becomes ...

$= (2 \pi)^{-1/2} e^{-x^2 / 2}$

## d

$X \to \mathcal{N}(0, 1)$, so $X^2 \to \chi^2_1$

## e

$F_{q, p}$ would be the sum of $q$ $t_p$ distributed random variables, so as 
$p \to \infty$, $F_{q, p} \to \chi^2_q$